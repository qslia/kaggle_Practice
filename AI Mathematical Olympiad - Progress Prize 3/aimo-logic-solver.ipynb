{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f30687",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/ashsihkumar/aimo-logic-solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9954b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T08:46:28.787689Z",
     "iopub.status.busy": "2026-02-21T08:46:28.787391Z",
     "iopub.status.idle": "2026-02-21T08:53:54.596374Z",
     "shell.execute_reply": "2026-02-21T08:53:54.595825Z"
    },
    "papermill": {
     "duration": 445.81474,
     "end_time": "2026-02-21T08:53:54.597437",
     "exception": false,
     "start_time": "2026-02-21T08:46:28.782697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyldavis 3.4.1 requires scikit-learn>=1.0.0, which is not installed.\n",
      "ydata-profiling 4.18.1 requires matplotlib<=3.10,>=3.5, which is not installed.\n",
      "stable-baselines3 2.1.0 requires matplotlib, which is not installed.\n",
      "sentence-transformers 5.1.1 requires scikit-learn, which is not installed.\n",
      "librosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\n",
      "cuml-cu12 25.6.0 requires scikit-learn>=1.5, which is not installed.\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "bigframes 2.26.0 requires matplotlib>=3.7.1, which is not installed.\n",
      "arviz 0.22.0 requires matplotlib>=3.8, which is not installed.\n",
      "pynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\n",
      "shap 0.49.1 requires scikit-learn, which is not installed.\n",
      "fastai 2.8.4 requires matplotlib, which is not installed.\n",
      "fastai 2.8.4 requires scikit-learn, which is not installed.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, which is not installed.\n",
      "cudf-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
      "cuml-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "pylibraft-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "cuvs-cu12 25.6.1 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "fastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cu128 which is incompatible.\n",
      "rmm-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
      "2026-02-21 08:49:50,356 [INFO] Preloading model weights...\n",
      "2026-02-21 08:51:15,035 [INFO] Preloaded 65.28 GB in 84.7s\n",
      "2026-02-21 08:51:15,239 [INFO] Waiting for vLLM server...\n",
      "2026-02-21 08:53:24,923 [INFO] Server ready in 129.7s\n",
      "2026-02-21 08:53:25,055 [INFO] Starting 16 Jupyter kernels...\n",
      "2026-02-21 08:53:27,936 [INFO] Kernels ready in 2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Problem: Solve $4+x=4$ for $x$.\n",
      "Type=general | Difficulty=medium | Budget=900s | 7 TIR + 5 COT\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 08:53:46,670 [INFO] Early stop: answer=0 with 6 votes (TIR-backed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attempt Type  Answer  PyErr  Tokens  Entropy  VerifyScore\n",
      "       0  TIR       0      0     201    0.423          0.0\n",
      "       5  TIR       0      0     201    0.564          0.0\n",
      "       4  TIR       0      0     201    0.479          0.0\n",
      "       9  COT       0      0     201    0.380          0.0\n",
      "       6  TIR       0      0     201    0.503          0.0\n",
      "       3  TIR       0      0     201    0.374          0.0\n",
      " Answer  Votes  Score  MinEntropy\n",
      "      0      6 13.522       0.374\n",
      "\n",
      "Final Answer: 0\n",
      "\n",
      "\n",
      "============================================================\n",
      "Problem: What is $0\\times10$?\n",
      "Type=general | Difficulty=medium | Budget=900s | 7 TIR + 5 COT\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 08:53:50,422 [INFO] Early stop: answer=0 with 6 votes (TIR-backed)\n",
      "2026-02-21 08:53:50,905 [WARNING] Attempt 6: parse error (Unexpected EOS while waiting for message header to complete), stopping turn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attempt Type  Answer  PyErr  Tokens  Entropy  VerifyScore\n",
      "      10  COT       0      0     114    0.181          0.0\n",
      "      11  COT       0      0     195    0.292          0.0\n",
      "       0  TIR       0      0     201    0.431          0.0\n",
      "       2  TIR       0      0     201    0.492          0.0\n",
      "       4  TIR       0      0     201    0.497          0.0\n",
      "       5  TIR       0      0     201    0.579          0.0\n",
      " Answer  Votes  Score  MinEntropy\n",
      "      0      6 14.591       0.181\n",
      "\n",
      "Final Answer: 0\n",
      "\n",
      "\n",
      "============================================================\n",
      "Problem: What is $1-1$?\n",
      "Type=general | Difficulty=medium | Budget=900s | 7 TIR + 5 COT\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 08:53:54,365 [INFO] Early stop: answer=0 with 6 votes (TIR-backed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attempt Type  Answer  PyErr  Tokens  Entropy  VerifyScore\n",
      "       9  COT       0      0     184    0.235          0.0\n",
      "       0  TIR       0      0     201    0.435          0.0\n",
      "       2  TIR       0      0     201    0.438          0.0\n",
      "       1  TIR       0      0     201    0.612          0.0\n",
      "       4  TIR       0      0     201    0.249          0.0\n",
      "       6  TIR       0      0     201    0.474          0.0\n",
      " Answer  Votes  Score  MinEntropy\n",
      "      0      6 16.253       0.235\n",
      "\n",
      "Final Answer: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Added -q to silence the long installation text\n",
    "%pip uninstall -y -q 'keras' 'matplotlib' 'scikit-learn' 'tensorflow'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def set_env(input_archive, temp_dir):\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "        subprocess.run(['tar', '-xzf', input_archive, '-C', temp_dir], check=True)\n",
    "    subprocess.run([\n",
    "        sys.executable, '-m', 'pip', 'install',\n",
    "        '--no-index', '--find-links', f'{temp_dir}/wheels',\n",
    "        '-q', 'unsloth', 'trl', 'vllm', 'openai_harmony'\n",
    "    ], check=True)\n",
    "\n",
    "set_env(\n",
    "    input_archive='/kaggle/input/aimo-3-utils/wheels.tar.gz',\n",
    "    temp_dir='/kaggle/tmp/setup'\n",
    ")\n",
    "\n",
    "os.environ['TRANSFORMERS_NO_TF']      = '1'\n",
    "os.environ['TRANSFORMERS_NO_FLAX']    = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']    = '0'\n",
    "os.environ['TOKENIZERS_PARALLELISM']  = 'false'\n",
    "os.environ['TRITON_PTXAS_PATH']       = '/usr/local/cuda/bin/ptxas'\n",
    "os.environ['TIKTOKEN_ENCODINGS_BASE'] = '/kaggle/tmp/setup/tiktoken_encodings'\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import queue\n",
    "import logging\n",
    "import threading\n",
    "import traceback\n",
    "import contextlib\n",
    "from typing import Optional\n",
    "from collections import Counter, defaultdict\n",
    "from concurrent.futures import as_completed, ThreadPoolExecutor\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from openai import OpenAI\n",
    "from jupyter_client import KernelManager\n",
    "from transformers import set_seed\n",
    "\n",
    "# --- Modified Logging Section ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
    "log = logging.getLogger('aimo3')\n",
    "\n",
    "# Silencing the noisy library logs (Retries and POST requests)\n",
    "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "# --------------------------------\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# CONFIGURATION\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class CFG:\n",
    "    served_model_name = 'gpt-oss'\n",
    "    model_path        = '/kaggle/input/gpt-oss-120b/transformers/default/1'\n",
    "    kv_cache_dtype    = 'fp8_e4m3'\n",
    "    dtype             = 'auto'\n",
    "\n",
    "    notebook_limit        = 17400\n",
    "    high_problem_timeout  = 900\n",
    "    base_problem_timeout  = 300\n",
    "    server_timeout        = 180\n",
    "\n",
    "    session_timeout   = 960\n",
    "    jupyter_timeout   = 8\n",
    "    sandbox_timeout   = 5 \n",
    "\n",
    "    stream_interval   = 200\n",
    "    context_tokens    = 65536\n",
    "    buffer_tokens     = 512\n",
    "    search_tokens     = 32\n",
    "    top_logprobs      = 5\n",
    "    batch_size        = 256\n",
    "\n",
    "    # Attempt split\n",
    "    tir_fraction    = 0.625\n",
    "    attempts_hard   = 12\n",
    "    attempts_medium = 12\n",
    "    early_stop      = 6\n",
    "    workers         = 16\n",
    "    turns           = 128\n",
    "\n",
    "    # Reflection\n",
    "    reflect_budget            = 1      \n",
    "    reflect_min_time_left     = 90     \n",
    "    reflect_only_on_conflict  = True   \n",
    "\n",
    "    # Memory guard\n",
    "    max_logprobs_buf = 2000  \n",
    "\n",
    "    # Scoring\n",
    "    entropy_override_ratio     = 2.0  \n",
    "    entropy_override_min_votes = 2   \n",
    "    error_penalty_factor       = 0.5\n",
    "    length_bonus_threshold     = 200  \n",
    "    length_bonus_min           = 0.5\n",
    "    verify_bonus_max           = 2.2 \n",
    "\n",
    "    seed                   = 42\n",
    "    gpu_memory_utilization = 0.96\n",
    "    min_p                  = 0.02\n",
    "\n",
    "    temperatures_by_type = {\n",
    "        'geometry':      [0.7, 0.8, 0.9, 1.0],\n",
    "        'number_theory': [0.8, 1.0, 1.2, 1.4],\n",
    "        'algebra':       [0.8, 1.0, 1.2, 1.4],\n",
    "        'combinatorics': [1.0, 1.2, 1.4, 1.6],\n",
    "        'general':       [0.8, 1.0, 1.2, 1.4],\n",
    "    }\n",
    "    temperature_verify = 0.2  \n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# PROMPTS\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class Prompts:\n",
    "\n",
    "    TOOL = (\n",
    "        'Use this tool to execute Python code. '\n",
    "        'The environment is a stateful Jupyter notebook. '\n",
    "        'You must use print() to output results.'\n",
    "    )\n",
    "\n",
    "    PREFERENCE = (\n",
    "        'You have access to `math`, `numpy`, `sympy`, `sympy.geometry`, '\n",
    "        'and `mpmath` (64-digit precision). '\n",
    "        'Common symbols x,y,z,a,b,c,n,k,r,t are pre-declared. '\n",
    "        'For geometry: coordinate bash + sympy.geometry. '\n",
    "        'For number theory: sympy.ntheory (factorint, isprime, totient). '\n",
    "        'For counting: brute-force small N first, then generalise. '\n",
    "        'End with a sympy assertion that verifies your answer.'\n",
    "    )\n",
    "\n",
    "    TIR = ( # Tool-Integrated Reasoning\n",
    "        \"You are a world-class IMO competitor.\\n\"\n",
    "        \"1. CATEGORIZE: Identify problem type (algebra/combinatorics/geometry/number-theory).\\n\"\n",
    "        \"2. PLAN: Mathematical approach + Python verification plan.\\n\"\n",
    "        \"3. SOLVE: Python with sympy/numpy/mpmath. Print intermediates.\\n\"\n",
    "        \"4. VERIFY: Separate Python block checking via a different method:\\n\"\n",
    "        \"   - Geometry   → verify constraints numerically\\n\"\n",
    "        \"   - Counting   → brute-force small cases\\n\"\n",
    "        \"   - Equations  → substitute back with sympy.simplify\\n\"\n",
    "        \"   - Mod arith  → check mod two different small primes\\n\"\n",
    "        \"5. ASSERT: `assert <condition>` in Python — if it fails, correct the answer.\\n\"\n",
    "        \"6. ANSWER: Final non-negative integer in \\\\boxed{}.\"\n",
    "    )\n",
    "\n",
    "    COT = (\n",
    "        \"You are an expert mathematician competing at IMO level. \"\n",
    "        \"Solve using PURE mathematical reasoning — no Python code.\\n\"\n",
    "        \"1. Read twice. Identify the key constraint.\\n\"\n",
    "        \"2. Reason step-by-step, verifying each deduction.\\n\"\n",
    "        \"3. Consider edge cases explicitly.\\n\"\n",
    "        \"4. Only state your final answer when you have high confidence.\\n\"\n",
    "        \"Final answer in \\\\boxed{}.\"\n",
    "    )\n",
    "\n",
    "    GEOMETRY_TIR = (\n",
    "        \"You are an expert in competition geometry.\\n\"\n",
    "        \"MANDATORY APPROACH:\\n\"\n",
    "        \"1. Immediately place all figures in coordinates.\\n\"\n",
    "        \"2. Use sympy.geometry (Point, Line, Circle, Triangle) for exact computation.\\n\"\n",
    "        \"3. Solve with sympy.solve(). Never rely on intuition alone.\\n\"\n",
    "        \"4. Verify the answer satisfies ALL original constraints numerically.\\n\"\n",
    "        \"5. `assert <geometric_condition>` before giving the answer.\\n\"\n",
    "        \"Final integer in \\\\boxed{}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    VERIFY = (\n",
    "        \"You are a strict mathematical verifier. NOT a solver.\\n\"\n",
    "        \"You have been given a candidate answer. Your ONLY job is to check it.\\n\\n\"\n",
    "        \"RULES:\\n\"\n",
    "        \"- Do NOT re-solve the problem from scratch.\\n\"\n",
    "        \"- Do NOT re-derive. Only substitute and check.\\n\"\n",
    "        \"- Write Python that plugs the candidate answer into every problem condition.\\n\"\n",
    "        \"- with an Each condition must be checked explicit `assert`.\\n\"\n",
    "        \"- If any `assert` fails: print 'INVALID: <which condition failed>' \"\n",
    "        \"and output \\\\boxed{wrong}.\\n\"\n",
    "        \"- If all `assert`s pass: print 'VALID' and output \\\\boxed{candidate_answer}.\\n\\n\"\n",
    "        \"Begin verification now. No planning. No exploration. Assert only.\"\n",
    "    )\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(problem: str, answer: int) -> str:\n",
    "        return (\n",
    "            f\"PROBLEM:\\n{problem}\\n\\n\"\n",
    "            f\"CANDIDATE ANSWER: {answer}\\n\\n\"\n",
    "            f\"Verify whether {answer} satisfies all conditions using Python assert statements.\"\n",
    "        )\n",
    "\n",
    "    DETERMINISTIC_VERIFY = (\n",
    "        \"You are the final arbiter for a competition math problem.\\n\"\n",
    "        \"Two candidate answers are in conflict. You must determine which is correct.\\n\\n\"\n",
    "        \"PROBLEM:\\n{problem}\\n\\n\"\n",
    "        \"CANDIDATE A: {answer_a}\\n\"\n",
    "        \"CANDIDATE B: {answer_b}\\n\\n\"\n",
    "        \"INSTRUCTIONS:\\n\"\n",
    "        \"1. Write Python that tests CANDIDATE A against every problem condition.\\n\"\n",
    "        \"   Use explicit `assert` for each condition. Print 'A:PASS' or 'A:FAIL:<reason>'.\\n\"\n",
    "        \"2. Write Python that tests CANDIDATE B against every problem condition.\\n\"\n",
    "        \"   Use explicit `assert` for each condition. Print 'B:PASS' or 'B:FAIL:<reason>'.\\n\"\n",
    "        \"3. Output ONLY \\\\boxed{{winning_candidate}} — the integer that passed.\\n\"\n",
    "        \"   If both fail, output \\\\boxed{{0}}.\\n\"\n",
    "        \"   If both pass, output the one with stronger verification.\\n\\n\"\n",
    "        \"No re-solving. No derivation. Substitution and assertion only.\"\n",
    "    )\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# PROBLEM CLASSIFIER\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "GEOMETRY_KEYWORDS = {\n",
    "    'triangle', 'circle', 'angle', 'perpendicular', 'tangent',\n",
    "    'polygon', 'quadrilateral', 'circumscribe', 'inscribe',\n",
    "    'chord', 'radius', 'area', 'perimeter', 'segment', 'altitude',\n",
    "    'median', 'bisector', 'cyclic', 'collinear', 'concurrent',\n",
    "    'hexagon', 'pentagon', 'diagonal', 'circumradius', 'inradius',\n",
    "    'orthocenter', 'centroid', 'incircle', 'excircle',\n",
    "}\n",
    "\n",
    "NUMBER_THEORY_KEYWORDS = {\n",
    "    'prime', 'divisib', 'modulo', 'remainder', 'diophantine',\n",
    "    'gcd', 'lcm', 'coprime', 'totient', 'congruent', 'factor',\n",
    "}\n",
    "\n",
    "ALGEBRA_KEYWORDS = {\n",
    "    'functional equation', 'polynomial', 'root', 'coefficient',\n",
    "    'sequence', 'series', 'inequality', 'maximum', 'minimum',\n",
    "}\n",
    "\n",
    "COMBINATORICS_KEYWORDS = {\n",
    "    'count', 'permut', 'combin', 'graph', 'arrangement',\n",
    "    'subset', 'partition', 'bijection', 'coloring', 'path',\n",
    "    'tournament', 'alice', 'bob', 'game',\n",
    "}\n",
    "\n",
    "HARD_KEYWORDS = (\n",
    "    GEOMETRY_KEYWORDS | NUMBER_THEORY_KEYWORDS |\n",
    "    ALGEBRA_KEYWORDS | COMBINATORICS_KEYWORDS\n",
    ")\n",
    "\n",
    "\n",
    "def detect_problem_type(problem: str) -> str:\n",
    "    p = problem.lower()\n",
    "    scores = {\n",
    "        'geometry':      sum(k in p for k in GEOMETRY_KEYWORDS),\n",
    "        'number_theory': sum(k in p for k in NUMBER_THEORY_KEYWORDS),\n",
    "        'algebra':       sum(k in p for k in ALGEBRA_KEYWORDS),\n",
    "        'combinatorics': sum(k in p for k in COMBINATORICS_KEYWORDS),\n",
    "    }\n",
    "    best = max(scores, key=scores.get)\n",
    "    return best if scores[best] > 0 else 'general'\n",
    "\n",
    "\n",
    "def estimate_difficulty(problem: str) -> str:\n",
    "    p = problem.lower()\n",
    "    hard_hits = sum(k in p for k in HARD_KEYWORDS)\n",
    "    if len(problem) > 400 or hard_hits >= 2:\n",
    "        return 'hard'\n",
    "    return 'medium'\n",
    "\n",
    "\n",
    "def select_system_prompt(ptype: str, is_tir: bool) -> str:\n",
    "    if ptype == 'geometry' and is_tir:\n",
    "        return Prompts.GEOMETRY_TIR   \n",
    "    if not is_tir:\n",
    "        return Prompts.COT            \n",
    "    return Prompts.TIR                \n",
    "# ─────────────────────────────────────────────\n",
    "# ERROR CATEGORIZER\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class ErrorKind:\n",
    "    NONE    = 'none'\n",
    "    TIMEOUT = 'timeout'\n",
    "    SYNTAX  = 'syntax'\n",
    "    RUNTIME = 'runtime'\n",
    "    OTHER   = 'other'\n",
    "\n",
    "\n",
    "def categorize_error(output: str) -> str:\n",
    "    if '[ERROR] Timed out' in output:\n",
    "        return ErrorKind.TIMEOUT\n",
    "    if 'SyntaxError' in output:\n",
    "        return ErrorKind.SYNTAX\n",
    "    if 'Traceback' in output or 'Error:' in output:\n",
    "        return ErrorKind.RUNTIME\n",
    "    if output.startswith('[ERROR]'):\n",
    "        return ErrorKind.OTHER\n",
    "    return ErrorKind.NONE\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# SANDBOX\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class Sandbox:\n",
    "\n",
    "    _port_lock = threading.Lock()\n",
    "    _next_port = 50000\n",
    "\n",
    "    @classmethod\n",
    "    def _get_ports(cls, n=5):\n",
    "        with cls._port_lock:\n",
    "            ports = list(range(cls._next_port, cls._next_port + n))\n",
    "            cls._next_port += n\n",
    "        return ports\n",
    "\n",
    "    def __init__(self, timeout: float):\n",
    "        self._timeout = timeout\n",
    "        self._km      = None\n",
    "        self._client  = None\n",
    "\n",
    "        ports = self._get_ports()\n",
    "        env   = os.environ.copy()\n",
    "        env.update({\n",
    "            'PYDEVD_DISABLE_FILE_VALIDATION': '1',\n",
    "            'PYDEVD_WARN_EVALUATION_TIMEOUT': '0',\n",
    "            'JUPYTER_PLATFORM_DIRS':          '1',\n",
    "            'PYTHONWARNINGS':                 'ignore',\n",
    "            'MPLBACKEND':                     'Agg',\n",
    "        })\n",
    "\n",
    "        self._km = KernelManager()\n",
    "        self._km.shell_port   = ports[0]\n",
    "        self._km.iopub_port   = ports[1]\n",
    "        self._km.stdin_port   = ports[2]\n",
    "        self._km.hb_port      = ports[3]\n",
    "        self._km.control_port = ports[4]\n",
    "        self._km.start_kernel(env=env, extra_arguments=['--Application.log_level=CRITICAL'])\n",
    "\n",
    "        self._client = self._km.blocking_client()\n",
    "        self._client.start_channels()\n",
    "        self._client.wait_for_ready(timeout=self._timeout)\n",
    "\n",
    "        self._preload()\n",
    "\n",
    "    def _preload(self):\n",
    "        self.execute(\n",
    "            'import math, numpy, sympy, itertools, collections, mpmath\\n'\n",
    "            'import sympy.ntheory as nt\\n'\n",
    "            'from sympy import *\\n'\n",
    "            'from sympy.geometry import *\\n'\n",
    "            'mpmath.mp.dps = 64\\n'\n",
    "            'x,y,z,a,b,c,n,k,r,t = symbols(\"x y z a b c n k r t\", real=True)\\n'\n",
    "        )\n",
    "\n",
    "    def _clean_tb(self, tb: list) -> str:\n",
    "        lines = []\n",
    "        for frame in tb:\n",
    "            f = re.sub(r'\\x1b\\[[0-9;]*m', '', frame)\n",
    "            if 'File \"' in f and 'ipython-input' not in f:\n",
    "                continue\n",
    "            lines.append(f)\n",
    "        return ''.join(lines)\n",
    "\n",
    "    def execute(self, code: str, timeout: float | None = None) -> str:\n",
    "        client      = self._client\n",
    "        eff_timeout = timeout or self._timeout\n",
    "        msg_id      = client.execute(code, store_history=True, allow_stdin=False, stop_on_error=False)\n",
    "\n",
    "        stdout, stderr = [], []\n",
    "        start = time.time()\n",
    "\n",
    "        while True:\n",
    "            if time.time() - start > eff_timeout:\n",
    "                self._km.interrupt_kernel()\n",
    "                return f'[ERROR] Timed out after {eff_timeout}s'\n",
    "            try:\n",
    "                msg = client.get_iopub_msg(timeout=1.0)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "            if msg.get('parent_header', {}).get('msg_id') != msg_id:\n",
    "                continue\n",
    "\n",
    "            mtype   = msg.get('msg_type')\n",
    "            content = msg.get('content', {})\n",
    "\n",
    "            if mtype == 'stream':\n",
    "                target = stdout if content.get('name') == 'stdout' else stderr\n",
    "                target.append(content.get('text', ''))\n",
    "            elif mtype == 'error':\n",
    "                stderr.append(self._clean_tb(content.get('traceback', [])))\n",
    "            elif mtype in {'execute_result', 'display_data'}:\n",
    "                text = content.get('data', {}).get('text/plain')\n",
    "                if text:\n",
    "                    stdout.append(text if text.endswith('\\n') else text + '\\n')\n",
    "            elif mtype == 'status' and content.get('execution_state') == 'idle':\n",
    "                break\n",
    "\n",
    "        out = ''.join(stdout)\n",
    "        err = ''.join(stderr)\n",
    "        if err:\n",
    "            return f'{out.rstrip()}\\n{err}' if out else err\n",
    "        return out if out.strip() else '[WARN] No output. Use print().'\n",
    "\n",
    "    def reset(self):\n",
    "        self.execute('%reset -f')\n",
    "        self._preload()\n",
    "\n",
    "    def close(self):\n",
    "        with contextlib.suppress(Exception):\n",
    "            if self._client:\n",
    "                self._client.stop_channels()\n",
    "        if self._km:\n",
    "            with contextlib.suppress(Exception):\n",
    "                self._km.shutdown_kernel(now=True)\n",
    "            with contextlib.suppress(Exception):\n",
    "                self._km.cleanup_resources()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# OPENAI-HARMONY IMPORTS\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "from openai_harmony import (\n",
    "    HarmonyEncodingName, load_harmony_encoding,\n",
    "    SystemContent, ReasoningEffort, ToolNamespaceConfig,\n",
    "    Author, Message, Role, TextContent, Conversation,\n",
    ")\n",
    "\n",
    "\n",
    "class AIMO3Template:\n",
    "    \"\"\"\n",
    "    Owns all openai_harmony formatting logic.\n",
    "\n",
    "    Centralises the contract between our prompts and the harmony\n",
    "    message format so no call site has to know about SystemContent,\n",
    "    ReasoningEffort, or ToolNamespaceConfig construction details.\n",
    "\n",
    "    IMPORTANT: tool_config is embedded into the Conversation via\n",
    "    SystemContent.with_tools() at build time. Do NOT pass it again\n",
    "    as a third argument to render_conversation_for_completion().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tool_prompt: str):\n",
    "        self._tool_config = ToolNamespaceConfig(\n",
    "            name='python',\n",
    "            description=tool_prompt,\n",
    "            tools=[],\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def tool_config(self) -> ToolNamespaceConfig:\n",
    "        \"\"\"The ToolNamespaceConfig embedded in the system message.\"\"\"\n",
    "        return self._tool_config\n",
    "\n",
    "    def build_conversation(\n",
    "        self,\n",
    "        system_prompt: str,\n",
    "        user_prompt:   str,\n",
    "    ) -> Conversation:\n",
    "        \"\"\"\n",
    "        Returns a ready-to-render Conversation from a system + user prompt pair.\n",
    "        Applies HIGH reasoning effort and attaches the python tool namespace.\n",
    "        \"\"\"\n",
    "        messages = self._make_messages(system_prompt, user_prompt)\n",
    "        return Conversation.from_messages(messages)\n",
    "\n",
    "    def make_tool_response(\n",
    "        self,\n",
    "        output:  str,\n",
    "        channel: str | None = None,\n",
    "    ) -> Message:\n",
    "        \"\"\"Wraps a Python kernel output string into a TOOL-role Message.\"\"\"\n",
    "        msg = Message(\n",
    "            author=Author(role=Role.TOOL, name='python'),\n",
    "            content=[TextContent(text=output)],\n",
    "        ).with_recipient('assistant')\n",
    "        return msg.with_channel(channel) if channel else msg\n",
    "\n",
    "    def _make_system_content(self, system_prompt: str) -> SystemContent:\n",
    "        return (\n",
    "            SystemContent.new()\n",
    "            .with_model_identity(system_prompt)\n",
    "            .with_reasoning_effort(ReasoningEffort.HIGH)\n",
    "            .with_tools(self._tool_config)\n",
    "        )\n",
    "\n",
    "    def _make_messages(self, system_prompt: str, user_prompt: str) -> list[Message]:\n",
    "        system_content = self._make_system_content(system_prompt)\n",
    "        return [\n",
    "            Message.from_role_and_content(Role.SYSTEM, system_content),\n",
    "            Message.from_role_and_content(Role.USER,   user_prompt),\n",
    "        ]\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# TOOL EXECUTOR\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class Tool:\n",
    "\n",
    "    def __init__(self, sandbox: Sandbox, template: 'AIMO3Template'):\n",
    "        self._sandbox  = sandbox\n",
    "        self._template = template\n",
    "        self._lock     = threading.Lock()\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_print(code: str) -> str:\n",
    "        lines = code.strip().split('\\n')\n",
    "        if not lines:\n",
    "            return code\n",
    "        last = lines[-1].strip()\n",
    "        if any(kw in last for kw in ('print', 'import', '#')) or not last:\n",
    "            return code\n",
    "        lines[-1] = f'print({last})'\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "    def call(self, message: Message) -> tuple[list[Message], str]:\n",
    "        \"\"\"\n",
    "        Execute code from a model tool-call message.\n",
    "        Returns (response_messages, error_kind).\n",
    "        Uses the template to build the response message so all\n",
    "        openai_harmony formatting stays in one place.\n",
    "        \"\"\"\n",
    "        code = self._ensure_print(message.content[0].text)\n",
    "        with self._lock:\n",
    "            try:\n",
    "                output = self._sandbox.execute(code)\n",
    "            except Exception as exc:\n",
    "                log.warning('Tool execution exception: %s', exc)\n",
    "                output = f'[ERROR] {exc}'\n",
    "        kind     = categorize_error(output)\n",
    "        response = self._template.make_tool_response(output, channel=message.channel)\n",
    "        return [response], kind\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# ANSWER EXTRACTION\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "def scan_for_answer(text: str) -> int | None:\n",
    "    for pattern in [\n",
    "        r'\\\\boxed\\s*\\{\\s*([0-9,]+)\\s*\\}',\n",
    "        r'final\\s+answer\\s+is\\s*([0-9,]+)',\n",
    "        r'answer\\s*[=:]\\s*([0-9,]+)',\n",
    "    ]:\n",
    "        for match in reversed(re.findall(pattern, text, re.IGNORECASE)):\n",
    "            try:\n",
    "                val = int(match.replace(',', ''))\n",
    "                if 0 <= val <= 99999:\n",
    "                    return val\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# RESULT DATACLASS\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class AttemptResult:\n",
    "    \"\"\"Holds everything about one attempt including verification score.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.answer:          int | None = None\n",
    "        self.response_length: int        = 0\n",
    "        self.python_calls:    int        = 0\n",
    "        self.python_errors:   int        = 0\n",
    "        self.error_kinds:     list       = []   # list of ErrorKind strings\n",
    "        self.entropy:         float      = float('inf')\n",
    "        self.verify_score:    float      = 0.0  # 0.0–1.0\n",
    "        self.prompt_type:     str        = 'TIR'\n",
    "        self.attempt_idx:     int        = 0\n",
    "        self.is_reflection:   bool       = False\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            'Attempt':     self.attempt_idx,\n",
    "            'Type':        self.prompt_type,   # VERIFY / DET_VERIFY / TIR / GEO / COT\n",
    "            'Answer':      self.answer,        # kept as int | None; cast to Int64 at display time\n",
    "            'PyErr':       self.python_errors,\n",
    "            'Tokens':      self.response_length,\n",
    "            'Entropy':     round(self.entropy, 3),\n",
    "            'VerifyScore': round(self.verify_score, 2),\n",
    "        }\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# REFLECTION MANAGER\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class ReflectionManager:\n",
    "    \"\"\"Tracks reflection budget per problem.\"\"\"\n",
    "\n",
    "    def __init__(self, budget: int):\n",
    "        self._budget = budget\n",
    "        self._used   = 0\n",
    "        self._lock   = threading.Lock()\n",
    "\n",
    "    def can_reflect(self) -> bool:\n",
    "        with self._lock:\n",
    "            return self._used < self._budget\n",
    "\n",
    "    def consume(self) -> bool:\n",
    "        with self._lock:\n",
    "            if self._used < self._budget:\n",
    "                self._used += 1\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "    def reset(self):\n",
    "        with self._lock:\n",
    "            self._used = 0\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# CORE ATTEMPT RUNNER\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "def _compute_confidence_proxy(logprobs_buf: list) -> float:\n",
    "    \"\"\"\n",
    "    Confidence proxy using peak logprob rather than truncated Shannon entropy.\n",
    "\n",
    "    Why peak logprob instead of Shannon entropy:\n",
    "      - top_logprobs only covers 5 tokens — the tail mass is missing.\n",
    "      - Partial-distribution Shannon entropy is systematically underestimated,\n",
    "        making high-confidence tokens appear less certain than they are.\n",
    "      - Peak logprob (= log P(most likely token)) is stable regardless of\n",
    "        truncation because it never depends on the missing tail.\n",
    "      - We return the MEAN peak logprob across all tokens, then negate it\n",
    "        so the result behaves like entropy: lower = more confident.\n",
    "\n",
    "    Returns: mean(-max_logprob) across tokens.\n",
    "             Lower value  → more confident → higher weight in scoring.\n",
    "             float('inf') when no logprobs available.\n",
    "    \"\"\"\n",
    "    if not logprobs_buf:\n",
    "        return float('inf')\n",
    "\n",
    "    total, count = 0.0, 0\n",
    "    for lp_dict in logprobs_buf:\n",
    "        if not isinstance(lp_dict, dict) or not lp_dict:\n",
    "            continue\n",
    "        peak = max(lp_dict.values())   \n",
    "        total += peak\n",
    "        count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    mean_peak = total / count\n",
    "    return -mean_peak  \n",
    "\n",
    "\n",
    "def run_attempt(\n",
    "    client,\n",
    "    encoding,\n",
    "    stop_token_ids,\n",
    "    cfg:           CFG,\n",
    "    template:      AIMO3Template,\n",
    "    tool:          Tool,\n",
    "    system_prompt: str,\n",
    "    user_prompt:   str,\n",
    "    attempt_seed:  int,\n",
    "    stop_event:    threading.Event,\n",
    "    deadline:      float,\n",
    "    prompt_type:   str        = 'TIR',\n",
    "    attempt_idx:   int        = 0,\n",
    "    is_reflection: bool       = False,\n",
    "    temperature:   float | None = None,\n",
    ") -> AttemptResult:\n",
    "\n",
    "    result               = AttemptResult()\n",
    "    result.prompt_type   = prompt_type\n",
    "    result.attempt_idx   = attempt_idx\n",
    "    result.is_reflection = is_reflection\n",
    "\n",
    "    effective_temp = temperature if temperature is not None else cfg.temperatures_by_type['general'][0]\n",
    "\n",
    "    logprobs_buf: list = []\n",
    "\n",
    "    conversation = template.build_conversation(system_prompt, user_prompt)\n",
    "\n",
    "    try:\n",
    "        for _ in range(cfg.turns):\n",
    "            if stop_event.is_set() or time.time() > deadline:\n",
    "                break\n",
    "\n",
    "            # FIX 1: 2 args only — tool_config already baked into conversation\n",
    "            prompt_ids = encoding.render_conversation_for_completion(\n",
    "                conversation, Role.ASSISTANT\n",
    "            )\n",
    "            max_tokens = cfg.context_tokens - len(prompt_ids)\n",
    "            if max_tokens < cfg.buffer_tokens:\n",
    "                log.debug('Context full at attempt %d', attempt_idx)\n",
    "                break\n",
    "\n",
    "            stream = client.completions.create(\n",
    "                model=cfg.served_model_name,\n",
    "                temperature=effective_temp,\n",
    "                logprobs=cfg.top_logprobs,\n",
    "                max_tokens=max_tokens,\n",
    "                prompt=prompt_ids,\n",
    "                seed=attempt_seed,\n",
    "                stream=True,\n",
    "                extra_body={\n",
    "                    'min_p':            cfg.min_p,\n",
    "                    'stop_token_ids':   stop_token_ids,\n",
    "                    'return_token_ids': True,\n",
    "                },\n",
    "            )\n",
    "\n",
    "            token_buf   = []\n",
    "            text_chunks = []\n",
    "\n",
    "            try:\n",
    "                for chunk in stream:\n",
    "                    if stop_event.is_set() or time.time() > deadline:\n",
    "                        break\n",
    "\n",
    "                    new_tokens = chunk.choices[0].token_ids\n",
    "                    new_text   = chunk.choices[0].text\n",
    "\n",
    "                    if new_tokens:\n",
    "                        token_buf.extend(new_tokens)\n",
    "                        result.response_length += len(new_tokens)\n",
    "                        text_chunks.append(new_text)\n",
    "\n",
    "                        lp = chunk.choices[0].logprobs\n",
    "                        if lp and lp.top_logprobs:\n",
    "                            logprobs_buf.extend(lp.top_logprobs)\n",
    "                            # Memory guard: cap buffer\n",
    "                            if len(logprobs_buf) > cfg.max_logprobs_buf:\n",
    "                                logprobs_buf = logprobs_buf[-cfg.max_logprobs_buf:]\n",
    "\n",
    "                    if '}' in new_text:\n",
    "                        search = ''.join(text_chunks[-cfg.search_tokens:])\n",
    "                        ans    = scan_for_answer(search)\n",
    "                        if ans is not None:\n",
    "                            result.answer = ans\n",
    "                            break\n",
    "            finally:\n",
    "                stream.close()\n",
    "\n",
    "            if result.answer is not None:\n",
    "                break\n",
    "            if not token_buf:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                new_msgs = encoding.parse_messages_from_completion_tokens(token_buf, Role.ASSISTANT)\n",
    "            except Exception as exc:\n",
    "                log.warning('Attempt %d: parse error (%s), stopping turn', attempt_idx, exc)\n",
    "                break\n",
    "\n",
    "            conversation.messages.extend(new_msgs)\n",
    "            last_msg = new_msgs[-1]\n",
    "\n",
    "            if last_msg.channel == 'final':\n",
    "                result.answer = scan_for_answer(last_msg.content[0].text)\n",
    "                break\n",
    "\n",
    "            if last_msg.recipient == 'python':\n",
    "                result.python_calls += 1\n",
    "                responses, err_kind  = tool.call(last_msg)\n",
    "\n",
    "                if err_kind != ErrorKind.NONE:\n",
    "                    result.python_errors += 1\n",
    "                    result.error_kinds.append(err_kind)\n",
    "\n",
    "                conversation.messages.extend(responses)\n",
    "\n",
    "    except TimeoutError as exc:\n",
    "        log.warning('Attempt %d timed out: %s', attempt_idx, exc)\n",
    "        result.error_kinds.append(ErrorKind.TIMEOUT)\n",
    "\n",
    "    except ConnectionError as exc:\n",
    "        log.error('Attempt %d connection error: %s', attempt_idx, exc)\n",
    "        result.error_kinds.append(ErrorKind.OTHER)\n",
    "\n",
    "    except Exception as exc:\n",
    "        # Last-resort catch — always log with traceback for debugging\n",
    "        log.error('Attempt %d unexpected error:\\n%s', attempt_idx, traceback.format_exc())\n",
    "        result.error_kinds.append(ErrorKind.OTHER)\n",
    "\n",
    "    result.entropy = _compute_confidence_proxy(logprobs_buf)\n",
    "    return result\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# REFLECTION RUNNER\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "def run_reflection_attempt(\n",
    "    client, encoding, stop_token_ids, cfg, template: AIMO3Template, tool,\n",
    "    original_problem: str,\n",
    "    candidate_answer: int,\n",
    "    stop_event: threading.Event,\n",
    "    deadline:   float,\n",
    ") -> AttemptResult:\n",
    "    \"\"\"\n",
    "    Strict verification pass — substitution only, no re-solving.\n",
    "    Uses Prompts.VERIFY (not TIR) and lower temperature to reduce exploration.\n",
    "    \"\"\"\n",
    "    result = run_attempt(\n",
    "        client, encoding, stop_token_ids, cfg,\n",
    "        template, tool,\n",
    "        system_prompt = Prompts.VERIFY,          # strict verifier, not TIR\n",
    "        user_prompt   = Prompts.verify(original_problem, candidate_answer),\n",
    "        attempt_seed  = 999_999,\n",
    "        stop_event    = stop_event,\n",
    "        deadline      = deadline,\n",
    "        prompt_type   = 'VERIFY',\n",
    "        attempt_idx   = 99,\n",
    "        is_reflection = True,\n",
    "        temperature   = 0.4,                    \n",
    "    )\n",
    "\n",
    "    if result.answer is not None:\n",
    "        if result.answer == candidate_answer:\n",
    "            # Passed all assertions → high verify_score\n",
    "            result.verify_score = min(1.0, 0.7 + (1.0 / max(result.entropy, 0.1)) * 0.05)\n",
    "        else:\n",
    "\n",
    "            result.verify_score = 0.35\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_deterministic_verifier(\n",
    "    client, encoding, stop_token_ids, cfg, template: AIMO3Template, tool,\n",
    "    problem:    str,\n",
    "    answer_a:   int,\n",
    "    answer_b:   int,\n",
    "    stop_event: threading.Event,\n",
    "    deadline:   float,\n",
    ") -> int | None:\n",
    "    \"\"\"\n",
    "    Final arbiter at temperature=0.2.\n",
    "    Given two conflicting candidates, runs strict assertion-based verification\n",
    "    of both and returns the winner, or None if indeterminate.\n",
    "    Costs ~30-60s but resolves genuine conflicts reliably.\n",
    "    \"\"\"\n",
    "    user_prompt = Prompts.DETERMINISTIC_VERIFY.format(\n",
    "        problem=problem,\n",
    "        answer_a=answer_a,\n",
    "        answer_b=answer_b,\n",
    "    )\n",
    "    result = run_attempt(\n",
    "        client, encoding, stop_token_ids, cfg,\n",
    "        template, tool,\n",
    "        system_prompt = Prompts.VERIFY,\n",
    "        user_prompt   = user_prompt,\n",
    "        attempt_seed  = 777_777,\n",
    "        stop_event    = stop_event,\n",
    "        deadline      = deadline,\n",
    "        prompt_type   = 'DET_VERIFY',\n",
    "        attempt_idx   = 98,\n",
    "        is_reflection = True,\n",
    "        temperature   = cfg.temperature_verify,   # 0.2 — nearly deterministic\n",
    "    )\n",
    "\n",
    "    if result.answer in (answer_a, answer_b):\n",
    "        log.info('Deterministic verifier chose: %d', result.answer)\n",
    "        return result.answer\n",
    "\n",
    "    log.warning('Deterministic verifier returned unexpected answer: %s', result.answer)\n",
    "    return None\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# ANSWER SELECTION\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "def select_answer(results: list[AttemptResult], cfg: CFG) -> int:\n",
    "\n",
    "    answer_weights = defaultdict(float)\n",
    "    answer_votes   = defaultdict(int)\n",
    "    answer_min_ent = {}\n",
    "\n",
    "    for r in results:\n",
    "        if r.answer is None:\n",
    "            continue  \n",
    "\n",
    "        weight = 1.0 / max(r.entropy, 1e-9)\n",
    "\n",
    "        runtime_errors = r.error_kinds.count(ErrorKind.RUNTIME)\n",
    "        timeout_errors = r.error_kinds.count(ErrorKind.TIMEOUT)\n",
    "        syntax_errors  = r.error_kinds.count(ErrorKind.SYNTAX)\n",
    "        error_load = runtime_errors + timeout_errors * 1.5 + syntax_errors * 0.5\n",
    "        weight *= 1.0 / (1 + error_load * cfg.error_penalty_factor)\n",
    "\n",
    "        if r.response_length < cfg.length_bonus_threshold:\n",
    "            length_factor = max(\n",
    "                cfg.length_bonus_min,\n",
    "                r.response_length / cfg.length_bonus_threshold,\n",
    "            )\n",
    "            weight *= length_factor\n",
    "\n",
    "        if r.verify_score > 0:\n",
    "            verify_mult = 1.0 + r.verify_score * (cfg.verify_bonus_max - 1.0)\n",
    "            weight *= verify_mult\n",
    "\n",
    "        answer_weights[r.answer] += weight\n",
    "        answer_votes[r.answer]   += 1\n",
    "\n",
    "        if r.answer not in answer_min_ent or r.entropy < answer_min_ent[r.answer]:\n",
    "            answer_min_ent[r.answer] = r.entropy\n",
    "\n",
    "    if not answer_weights:\n",
    "        log.warning('No valid answers from any attempt. Returning 0.')\n",
    "        return 0\n",
    "\n",
    "\n",
    "    majority_ans = max(answer_votes,   key=answer_votes.get)\n",
    "    best_ent_ans = min(answer_min_ent, key=answer_min_ent.get)\n",
    "\n",
    "    if best_ent_ans != majority_ans:\n",
    "        minority_votes = answer_votes[best_ent_ans]\n",
    "        maj_ent        = answer_min_ent.get(majority_ans, float('inf'))\n",
    "        min_ent        = answer_min_ent[best_ent_ans]\n",
    "        vote_qualified = minority_votes >= cfg.entropy_override_min_votes\n",
    "        conf_qualified = min_ent * cfg.entropy_override_ratio < maj_ent\n",
    "\n",
    "        if vote_qualified and conf_qualified:\n",
    "            log.info(\n",
    "                'Entropy override: %d (proxy=%.3f, votes=%d) → %d (proxy=%.3f, votes=%d)',\n",
    "                majority_ans, maj_ent, answer_votes[majority_ans],\n",
    "                best_ent_ans, min_ent, minority_votes,\n",
    "            )\n",
    "            final = best_ent_ans\n",
    "        else:\n",
    "            final = max(answer_weights, key=answer_weights.get)\n",
    "    else:\n",
    "        final = max(answer_weights, key=answer_weights.get)\n",
    "\n",
    "    rows = []\n",
    "    for ans, w in sorted(answer_weights.items(), key=lambda x: -x[1]):\n",
    "        rows.append({\n",
    "            'Answer':     ans,\n",
    "            'Votes':      answer_votes[ans],\n",
    "            'Score':      round(w, 3),\n",
    "            'MinEntropy': round(answer_min_ent[ans], 3),\n",
    "        })\n",
    "    print(pd.DataFrame(rows).to_string(index=False))\n",
    "    print(f'\\nFinal Answer: {final}\\n')\n",
    "    return final\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# MAIN SOLVER\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "class Solver:\n",
    "\n",
    "    def __init__(self, cfg: CFG, port: int = 8000):\n",
    "        self.cfg  = cfg\n",
    "        self.port = port\n",
    "\n",
    "        self._preload_weights()\n",
    "        self.server_process = self._start_server()\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            base_url=f'http://0.0.0.0:{port}/v1',\n",
    "            api_key='sk-local',\n",
    "            timeout=cfg.session_timeout,\n",
    "        )\n",
    "        self._wait_for_server()\n",
    "\n",
    "        self.encoding       = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n",
    "        self.stop_token_ids = self.encoding.stop_tokens_for_assistant_actions()\n",
    "        self.template       = AIMO3Template(Prompts.TOOL)   # single template instance\n",
    "\n",
    "        self._init_kernels()\n",
    "        self.notebook_start = time.time()\n",
    "        self.problems_left  = 50\n",
    "\n",
    "    # ── server ─────────────────────────────────\n",
    "\n",
    "    def _preload_weights(self):\n",
    "        log.info('Preloading model weights...')\n",
    "        t0 = time.time()\n",
    "        files, total = [], 0\n",
    "        for root, _, fnames in os.walk(self.cfg.model_path):\n",
    "            for f in fnames:\n",
    "                p = os.path.join(root, f)\n",
    "                if os.path.isfile(p):\n",
    "                    files.append(p)\n",
    "                    total += os.path.getsize(p)\n",
    "\n",
    "        def _read(path):\n",
    "            with open(path, 'rb') as fh:\n",
    "                while fh.read(1 << 30):\n",
    "                    pass\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.cfg.workers) as ex:\n",
    "            list(ex.map(_read, files))\n",
    "        log.info('Preloaded %.2f GB in %.1fs', total / 1e9, time.time() - t0)\n",
    "\n",
    "    def _start_server(self):\n",
    "        cmd = [\n",
    "            sys.executable, '-m', 'vllm.entrypoints.openai.api_server',\n",
    "            '--seed',                   str(self.cfg.seed),\n",
    "            '--model',                  self.cfg.model_path,\n",
    "            '--served-model-name',      self.cfg.served_model_name,\n",
    "            '--tensor-parallel-size',   '1',\n",
    "            '--max-num-seqs',           str(self.cfg.batch_size),\n",
    "            '--gpu-memory-utilization', str(self.cfg.gpu_memory_utilization),\n",
    "            '--host',                   '0.0.0.0',\n",
    "            '--port',                   str(self.port),\n",
    "            '--dtype',                  self.cfg.dtype,\n",
    "            '--kv-cache-dtype',         self.cfg.kv_cache_dtype,\n",
    "            '--max-model-len',          str(self.cfg.context_tokens),\n",
    "            '--stream-interval',        str(self.cfg.stream_interval),\n",
    "            '--async-scheduling',\n",
    "            '--disable-log-stats',\n",
    "            '--enable-prefix-caching',\n",
    "        ]\n",
    "        self.log_file = open('vllm_server.log', 'w')\n",
    "        return subprocess.Popen(\n",
    "            cmd, stdout=self.log_file, stderr=subprocess.STDOUT, start_new_session=True,\n",
    "        )\n",
    "\n",
    "    def _wait_for_server(self):\n",
    "        log.info('Waiting for vLLM server...')\n",
    "        t0 = time.time()\n",
    "        for _ in range(self.cfg.server_timeout):\n",
    "            if self.server_process.poll() is not None:\n",
    "                raise RuntimeError('vLLM server died. Check vllm_server.log')\n",
    "            try:\n",
    "                self.client.models.list()\n",
    "                log.info('Server ready in %.1fs', time.time() - t0)\n",
    "                return\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "        raise RuntimeError('Server start timeout')\n",
    "\n",
    "    def _init_kernels(self):\n",
    "        log.info('Starting %d Jupyter kernels...', self.cfg.workers)\n",
    "        t0 = time.time()\n",
    "        self.sandbox_pool = queue.Queue()\n",
    "\n",
    "        def _mk():\n",
    "            return Sandbox(self.cfg.jupyter_timeout)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.cfg.workers) as ex:\n",
    "            futures = [ex.submit(_mk) for _ in range(self.cfg.workers)]\n",
    "            for f in as_completed(futures):\n",
    "                try:\n",
    "                    self.sandbox_pool.put(f.result())\n",
    "                except Exception as exc:\n",
    "                    log.error('Kernel init failed: %s', exc)\n",
    "\n",
    "        log.info('Kernels ready in %.1fs', time.time() - t0)\n",
    "\n",
    "    # ── budget ─────────────────────────────────\n",
    "\n",
    "    def _compute_budget(self) -> float:\n",
    "        elapsed   = time.time() - self.notebook_start\n",
    "        remaining = self.cfg.notebook_limit - elapsed\n",
    "        reserved  = max(0, self.problems_left - 1) * self.cfg.base_problem_timeout\n",
    "        budget    = min(remaining - reserved, self.cfg.high_problem_timeout)\n",
    "        return max(budget, self.cfg.base_problem_timeout)\n",
    "\n",
    "    # ── dispatch one attempt ───────────────────\n",
    "\n",
    "    def _dispatch(\n",
    "        self, problem: str, system_prompt: str, prompt_type: str,\n",
    "        attempt_idx: int, ptype: str,\n",
    "        stop_event: threading.Event, deadline: float,\n",
    "    ) -> AttemptResult:\n",
    "\n",
    "        empty = AttemptResult()\n",
    "        empty.attempt_idx = attempt_idx\n",
    "        empty.prompt_type = prompt_type\n",
    "\n",
    "        if stop_event.is_set() or time.time() > deadline:\n",
    "            return empty\n",
    "\n",
    "        sandbox = None\n",
    "        try:\n",
    "            sandbox = self.sandbox_pool.get(timeout=self.cfg.sandbox_timeout)\n",
    "            tool    = Tool(sandbox, self.template)\n",
    "            seed    = int((self.cfg.seed + attempt_idx) ** 2)\n",
    "\n",
    "            # Type-aware temperature: round-robin within the schedule for this problem type.\n",
    "            schedule = self.cfg.temperatures_by_type.get(ptype, self.cfg.temperatures_by_type['general'])\n",
    "            temp     = schedule[attempt_idx % len(schedule)]\n",
    "\n",
    "            return run_attempt(\n",
    "                self.client, self.encoding, self.stop_token_ids,\n",
    "                self.cfg, self.template, tool,\n",
    "                system_prompt = system_prompt,\n",
    "                user_prompt   = f'{problem}\\n\\n{Prompts.PREFERENCE}',\n",
    "                attempt_seed  = seed,\n",
    "                stop_event    = stop_event,\n",
    "                deadline      = deadline,\n",
    "                prompt_type   = prompt_type,\n",
    "                attempt_idx   = attempt_idx,\n",
    "                temperature   = temp,\n",
    "            )\n",
    "\n",
    "        except queue.Empty:\n",
    "            log.warning('Sandbox pool empty at attempt %d — skipping', attempt_idx)\n",
    "            return empty\n",
    "\n",
    "        except Exception:\n",
    "            log.error('Dispatch error at attempt %d:\\n%s', attempt_idx, traceback.format_exc())\n",
    "            return empty\n",
    "\n",
    "        finally:\n",
    "            if sandbox is not None:\n",
    "                try:\n",
    "                    sandbox.reset()\n",
    "                except Exception:\n",
    "                    pass\n",
    "                self.sandbox_pool.put(sandbox)\n",
    "\n",
    "    # ── main solve ─────────────────────────────\n",
    "\n",
    "    def solve(self, problem: str) -> int:\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        short = problem[:120] + '...' if len(problem) > 120 else problem\n",
    "        print(f'Problem: {short}')\n",
    "\n",
    "        ptype      = detect_problem_type(problem)\n",
    "        difficulty = estimate_difficulty(problem)\n",
    "        budget     = self._compute_budget()\n",
    "        deadline   = time.time() + budget\n",
    "\n",
    "        total = self.cfg.attempts_hard if difficulty == 'hard' else self.cfg.attempts_medium\n",
    "        n_tir = int(total * self.cfg.tir_fraction)\n",
    "        n_cot = total - n_tir\n",
    "\n",
    "        print(f'Type={ptype} | Difficulty={difficulty} | Budget={budget:.0f}s | '\n",
    "              f'{n_tir} TIR + {n_cot} COT\\n')\n",
    "\n",
    "        # Build task list\n",
    "        tasks = []\n",
    "        for i in range(n_tir):\n",
    "            sp = select_system_prompt(ptype, is_tir=True)\n",
    "            tasks.append((sp, 'TIR' if ptype != 'geometry' else 'GEO', i))\n",
    "        for i in range(n_cot):\n",
    "            tasks.append((Prompts.COT, 'COT', n_tir + i))\n",
    "\n",
    "        results:       list[AttemptResult] = []\n",
    "        valid_answers: list[int]           = []\n",
    "        stop_event  = threading.Event()\n",
    "        reflect_mgr = ReflectionManager(self.cfg.reflect_budget)\n",
    "\n",
    "        executor = ThreadPoolExecutor(max_workers=self.cfg.workers)\n",
    "        try:\n",
    "            futures = [\n",
    "                executor.submit(self._dispatch, problem, sp, ptype_label, idx, ptype, stop_event, deadline)\n",
    "                for sp, ptype_label, idx in tasks\n",
    "            ]\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    r = future.result()\n",
    "                    results.append(r)\n",
    "\n",
    "                    if r.answer is not None:\n",
    "                        valid_answers.append(r.answer)\n",
    "\n",
    "              \n",
    "                    counts = Counter(valid_answers).most_common(1)\n",
    "                    if counts and counts[0][1] >= self.cfg.early_stop:\n",
    "                        leading, vote_count = counts[0]\n",
    "\n",
    "                        tir_support = any(\n",
    "                            res.answer == leading and res.prompt_type in ('TIR', 'GEO')\n",
    "                            for res in results\n",
    "                        )\n",
    "\n",
    "                        if tir_support:\n",
    "                            log.info(\n",
    "                                'Early stop: answer=%d with %d votes (TIR-backed)',\n",
    "                                leading, vote_count,\n",
    "                            )\n",
    "                            stop_event.set()\n",
    "                            for f in futures:\n",
    "                                f.cancel()\n",
    "                            break\n",
    "                        else:\n",
    "                            log.info(\n",
    "                                'Early stop suppressed: answer=%d has %d votes but no TIR support',\n",
    "                                leading, vote_count,\n",
    "                            )\n",
    "\n",
    "                except Exception:\n",
    "                    log.error('Future result error:\\n%s', traceback.format_exc())\n",
    "\n",
    "        finally:\n",
    "            stop_event.set()\n",
    "            executor.shutdown(wait=True, cancel_futures=True)\n",
    "            self.problems_left = max(0, self.problems_left - 1)\n",
    "\n",
    "        if results:\n",
    "            df = pd.DataFrame([r.to_dict() for r in results])\n",
    "            df['Answer'] = df['Answer'].astype('Int64')\n",
    "            print(df.to_string(index=False))\n",
    "\n",
    "        if not valid_answers:\n",
    "            log.warning('No valid answers found. Returning 0.')\n",
    "            return 0\n",
    "\n",
    "        # ── Reflection pass ────────────────────\n",
    "        unique_answers = set(valid_answers)\n",
    "        time_left      = deadline - time.time()\n",
    "\n",
    "        run_reflect = (\n",
    "            reflect_mgr.can_reflect()\n",
    "            and time_left > self.cfg.reflect_min_time_left\n",
    "            and (not self.cfg.reflect_only_on_conflict or len(unique_answers) > 1)\n",
    "        )\n",
    "\n",
    "        if run_reflect and reflect_mgr.consume():\n",
    "            temp_weights: dict[int, float] = defaultdict(float)\n",
    "            for r in results:\n",
    "                if r.answer is not None:\n",
    "                    temp_weights[r.answer] += 1.0 / max(r.entropy, 1e-9)\n",
    "\n",
    "            top_candidates  = sorted(temp_weights, key=temp_weights.get, reverse=True)\n",
    "            reflect_targets = top_candidates[:2] if len(unique_answers) > 1 else top_candidates[:1]\n",
    "\n",
    "            if len(reflect_targets) == 2 and time_left < self.cfg.reflect_min_time_left * 2:\n",
    "                reflect_targets = reflect_targets[:1]\n",
    "\n",
    "            log.info('Reflecting on candidates: %s (%ds left)', reflect_targets, int(time_left))\n",
    "\n",
    "            reflect_results: dict[int, AttemptResult] = {}\n",
    "\n",
    "            for candidate in reflect_targets:\n",
    "                sandbox = None\n",
    "                try:\n",
    "                    sandbox     = self.sandbox_pool.get(timeout=self.cfg.sandbox_timeout)\n",
    "                    tool        = Tool(sandbox, self.template)\n",
    "                    reflect_stp = threading.Event()\n",
    "\n",
    "                    r_result = run_reflection_attempt(\n",
    "                        self.client, self.encoding, self.stop_token_ids, self.cfg,\n",
    "                        self.template, tool,\n",
    "                        original_problem = problem,\n",
    "                        candidate_answer = candidate,\n",
    "                        stop_event       = reflect_stp,\n",
    "                        deadline         = deadline,\n",
    "                    )\n",
    "                    reflect_results[candidate] = r_result\n",
    "                    results.append(r_result)\n",
    "\n",
    "                    if r_result.answer == candidate:\n",
    "                        for res in results:\n",
    "                            if res.answer == candidate and not res.is_reflection:\n",
    "                                res.verify_score = max(res.verify_score, 0.5)\n",
    "                        log.info('Reflection CONFIRMED: %d (verify_score=%.2f)', candidate, r_result.verify_score)\n",
    "                    elif r_result.answer is not None:\n",
    "                        log.info('Reflection CHANGED: %d → %d', candidate, r_result.answer)\n",
    "\n",
    "                except queue.Empty:\n",
    "                    log.warning('No sandbox for reflection of candidate=%d', candidate)\n",
    "                except Exception:\n",
    "                    log.error('Reflection error for candidate=%d:\\n%s', candidate, traceback.format_exc())\n",
    "                finally:\n",
    "                    if sandbox is not None:\n",
    "                        try:\n",
    "                            sandbox.reset()\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        self.sandbox_pool.put(sandbox)\n",
    "\n",
    "        # ── Deterministic verifier (top-2 conflict only) ──────\n",
    "        time_left = deadline - time.time()\n",
    "        weighted: dict[int, float] = defaultdict(float)\n",
    "        for r in results:\n",
    "            if r.answer is not None:\n",
    "                weighted[r.answer] += 1.0 / max(r.entropy, 1e-9)\n",
    "\n",
    "        if len(weighted) >= 2 and time_left > 45:\n",
    "            top2    = sorted(weighted, key=weighted.get, reverse=True)[:2]\n",
    "            gap     = weighted[top2[0]] - weighted[top2[1]]\n",
    "            total_w = sum(weighted.values())\n",
    "\n",
    "            # Only run if gap is less than 20% of total weight — genuinely close\n",
    "            if gap / max(total_w, 1e-9) < 0.20:\n",
    "                log.info(\n",
    "                    'Close conflict (gap=%.1f%%) — running deterministic verifier on %s',\n",
    "                    gap / total_w * 100, top2,\n",
    "                )\n",
    "                sandbox = None\n",
    "                try:\n",
    "                    sandbox  = self.sandbox_pool.get(timeout=self.cfg.sandbox_timeout)\n",
    "                    tool     = Tool(sandbox, self.template)\n",
    "                    det_stop = threading.Event()\n",
    "                    winner   = run_deterministic_verifier(\n",
    "                        self.client, self.encoding, self.stop_token_ids, self.cfg,\n",
    "                        self.template, tool,\n",
    "                        problem=problem,\n",
    "                        answer_a=top2[0],\n",
    "                        answer_b=top2[1],\n",
    "                        stop_event=det_stop,\n",
    "                        deadline=deadline,\n",
    "                    )\n",
    "                    if winner is not None:\n",
    "                        for r in results:\n",
    "                            if r.answer == winner and not r.is_reflection:\n",
    "                                r.verify_score = max(r.verify_score, 0.9)\n",
    "                        log.info('Deterministic verifier boosted: %d', winner)\n",
    "                except queue.Empty:\n",
    "                    log.warning('No sandbox for deterministic verifier')\n",
    "                except Exception:\n",
    "                    log.error('Deterministic verifier error:\\n%s', traceback.format_exc())\n",
    "                finally:\n",
    "                    if sandbox is not None:\n",
    "                        try:\n",
    "                            sandbox.reset()\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        self.sandbox_pool.put(sandbox)\n",
    "\n",
    "        return select_answer(results, self.cfg)\n",
    "\n",
    "    # ── cleanup ────────────────────────────────\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'server_process'):\n",
    "            with contextlib.suppress(Exception):\n",
    "                self.server_process.terminate()\n",
    "                self.server_process.wait()\n",
    "        if hasattr(self, 'log_file'):\n",
    "            with contextlib.suppress(Exception):\n",
    "                self.log_file.close()\n",
    "        if hasattr(self, 'sandbox_pool'):\n",
    "            while not self.sandbox_pool.empty():\n",
    "                with contextlib.suppress(Exception):\n",
    "                    self.sandbox_pool.get_nowait().close()\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# ENTRY POINT\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "set_seed(CFG.seed)\n",
    "solver = Solver(CFG)\n",
    "\n",
    "\n",
    "def predict(\n",
    "    id_: pl.DataFrame,\n",
    "    question: pl.DataFrame,\n",
    "    answer: Optional[pl.DataFrame] = None,\n",
    ") -> pl.DataFrame:\n",
    "\n",
    "    id_value      = id_.item(0)\n",
    "    question_text = question.item(0)\n",
    "\n",
    "    gc.disable()\n",
    "    final_answer = solver.solve(question_text)\n",
    "    gc.enable()\n",
    "    gc.collect()\n",
    "\n",
    "    return pl.DataFrame({'id': id_value, 'answer': final_answer})\n",
    "\n",
    "\n",
    "import kaggle_evaluation.aimo_3_inference_server\n",
    "inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        ('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv',)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf89f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T08:53:54.603664Z",
     "iopub.status.busy": "2026-02-21T08:53:54.603262Z",
     "iopub.status.idle": "2026-02-21T08:53:54.607964Z",
     "shell.execute_reply": "2026-02-21T08:53:54.607560Z"
    },
    "papermill": {
     "duration": 0.008897,
     "end_time": "2026-02-21T08:53:54.608917",
     "exception": false,
     "start_time": "2026-02-21T08:53:54.600020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "# import gc\n",
    "\n",
    "# # ============================================================================\n",
    "# # 1. THE OFFICIAL AIMO3 REFERENCE DATASET (NOV 2025)\n",
    "# # ============================================================================\n",
    "# AIMO3_REFERENCE_BENCH = [\n",
    "#     {\n",
    "#         \"id\": \"REF-01 (SWEETS)\",\n",
    "#         \"question\": \"Alice and Bob are each holding some integer number of sweets. Alice says to Bob: 'If we each added the number of sweets we’re holding to our (positive integer) age, my answer would be double yours. If we took the product, then my answer would be four times yours.' Bob replies: 'Why don’t you give me five of your sweets because then both our sum and product would be equal.' What is the product of Alice and Bob’s ages?\",\n",
    "#         \"answer\": 50\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-02 (RECTIL)\",\n",
    "#         \"question\": \"A 500 x 500 square is divided into k rectangles, each having integer side lengths. Given that no two of these rectangles have the same perimeter, the largest possible value of k is K. What is the remainder when K is divided by 10^5?\",\n",
    "#         \"answer\": 520\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-03 (MINPER)\",\n",
    "#         \"question\": \"Let ABC be an acute-angled triangle with integer side lengths and AB < AC. Points D and E lie on segments BC and AC, respectively, such that AD = AE = AB. Line DE intersects AB at X. Circles BXD and CED intersect for the second time at Y != D. Suppose that Y lies on line AD. There is a unique such triangle with minimal perimeter. This triangle has side lengths a = BC, b = CA, and c = AB. Find the remainder when abc is divided by 10^5.\",\n",
    "#         \"answer\": 336\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-04 (FUNVAL)\",\n",
    "#         \"question\": \"Let f: Z+ -> Z+ be a function such that for all positive integers m and n, f(m) + f(n) = f(m + n + mn). Across all functions f such that f(n) <= 1000 for all n <= 1000, how many different values can f(2024) take?\",\n",
    "#         \"answer\": 580\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-05 (RUNNERS)\",\n",
    "#         \"question\": \"A tournament is held with 2^20 runners each of which has a different running speed. In each race, two runners compete against each other with the faster runner always winning the race. The competition consists of 20 rounds with each runner starting with a score of 0. In each round, the runners are paired in such a way that in each pair, both runners have the same score at the beginning of the round. The winner of each race in the i-th round receives 2^(20-i) points and the loser gets no points. At the end of the tournament, we rank the competitors according to their scores. Let N denote the number of possible orderings of the competitors at the end of the tournament. Let k be the largest positive integer such that 10^k divides N. What is the remainder when k is divided by 10^5?\",\n",
    "#         \"answer\": 21818\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-06 (HERMITE)\",\n",
    "#         \"question\": \"Define a function f: Z+ -> Z+ by f(n) = sum_{i=1 to n} sum_{j=1 to n} j^1024 floor( 1/j + (n-i)/n ). Let M = 2*3*5*7*11*13 and let N = f(M^15) - f(M^15 - 1). Let k be the largest non-negative integer such that 2^k divides N. What is the remainder when 2^k is divided by 5^7?\",\n",
    "#         \"answer\": 32951\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-07 (N-TASTIC)\",\n",
    "#         \"question\": \"Let ABC be a triangle with AB != AC, circumcircle Omega, and incircle omega. Let the contact points of omega with BC, CA, and AB be D, E, and F, respectively. Let the circumcircle of AFE meet Omega at K and let the reflection of K in EF be K'. Let N denote the foot of the perpendicular from D to EF. The circle tangent to line BN and passing through B and K intersects BC again at T != B. Let sequence (Fn) be defined by F0 = 0, F1 = 1 and for n >= 2, Fn = Fn-1 + Fn-2. Call ABC n-tastic if BD = Fn, CD = Fn+1, and KNK'B is cyclic. Across all n-tastic triangles, let a_n denote the maximum possible value of (CT*NB)/(BT*NE). Let alpha denote the smallest real number such that for all sufficiently large n, a_{2n} < alpha. Given that alpha = p + sqrt(q) for rationals p and q, what is the remainder when floor(p^q) is divided by 99991?\",\n",
    "#         \"answer\": 57447\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-08 (DIGITSUM)\",\n",
    "#         \"question\": \"On a blackboard, Ken starts off by writing a positive integer n and then applies the following move until he first reaches 1. Given that the number on the board is m, he chooses a base b, where 2 <= b <= m, and considers the unique base-b representation of m. Ken then erases m on the blackboard and replaces it with the sum of its base-b digits. Across all choices of 1 <= n <= 10^{10^5}, the largest possible number of moves Ken could make is M. What is the remainder when M is divided by 10^5?\",\n",
    "#         \"answer\": 32193\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-09 (SHIFTY)\",\n",
    "#         \"question\": \"Let F be the set of functions alpha: Z -> Z for which there are only finitely many n in Z such that alpha(n) != 0. For two functions alpha and beta in F, define their product alpha * beta to be sum_{n in Z} alpha(n)*beta(n). Also, for n in Z, define a shift operator Sn: F -> F by Sn(alpha)(t) = alpha(t + n) for all t in Z. A function alpha in F is called shifty if alpha(m) = 0 for all integers m < 0 and m > 8 and there exists beta in F and integers k != l such that for all n in Z, Sn(alpha) * beta = 1 if n in {k, l} and 0 otherwise. How many shifty functions are there in F?\",\n",
    "#         \"answer\": 160\n",
    "#     },\n",
    "#     {\n",
    "#         \"id\": \"REF-10 (NORWEGIAN)\",\n",
    "#         \"question\": \"Let n >= 6 be a positive integer. We call a positive integer n-Norwegian if it has three distinct positive divisors whose sum is equal to n. Let f(n) denote the smallest n-Norwegian positive integer. Let M = 3^{2025!} and for a non-negative integer c define g(c) = floor( 2025! * f(M + c) / M ) / 2025!. We can write g(0) + g(4M) + g(1848374) + g(10162574) + g(265710644) + g(44636594) = p/q where p and q are coprime positive integers. What is the remainder when p + q is divided by 99991?\",\n",
    "#         \"answer\": 8687\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # ============================================================================\n",
    "# # 2. RUNNER LOGIC\n",
    "# # ============================================================================\n",
    "\n",
    "# def run_aimo3_reference_challenge():\n",
    "#     print(f\"\\n{'='*85}\")\n",
    "#     print(f\"🚀 STARTING OFFICIAL AIMO3 REFERENCE BENCHMARK (10 PROBLEMS)\")\n",
    "#     print(f\"Goal: Match frontier commercial models (9-10/10)\")\n",
    "#     print(f\"{'='*85}\\n\")\n",
    "    \n",
    "#     score_card = []\n",
    "#     correct_count = 0\n",
    "#     total_start = time.time()\n",
    "\n",
    "#     for item in AIMO3_REFERENCE_BENCH:\n",
    "#         prob_id = item['id']\n",
    "#         question_text = item['question']\n",
    "#         expected_answer = item['answer']\n",
    "        \n",
    "#         print(f\"📝 Testing {prob_id}...\")\n",
    "        \n",
    "#         # Prepare inputs as Polars DataFrames (simulating Kaggle environment)\n",
    "#         # Using [0,0] compatible extraction in the predict function\n",
    "#         id_df = pl.DataFrame({'id': [prob_id]})\n",
    "#         q_df = pl.DataFrame({'question': [question_text]})\n",
    "        \n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         try:\n",
    "#             # Invokes the user's predict function\n",
    "#             # Ensure predict() uses id_value = id_[0, 0] or similar\n",
    "#             output_df = predict(id_df, q_df)\n",
    "            \n",
    "#             # Extract the answer safely\n",
    "#             predicted_answer = int(output_df[0, \"answer\"])\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Error during solve of {prob_id}: {e}\")\n",
    "#             predicted_answer = -99999\n",
    "            \n",
    "#         duration = time.time() - start_time\n",
    "#         is_correct = (predicted_answer == expected_answer)\n",
    "        \n",
    "#         if is_correct:\n",
    "#             correct_count += 1\n",
    "#             status = \"✅ PASS\"\n",
    "#         else:\n",
    "#             status = f\"❌ FAIL (Exp: {expected_answer}, Got: {predicted_answer})\"\n",
    "            \n",
    "#         print(f\"Result: {status} | Time: {duration:.1f}s\\n\")\n",
    "        \n",
    "#         score_card.append({\n",
    "#             \"Problem\": prob_id,\n",
    "#             \"Result\": status,\n",
    "#             \"Time (s)\": round(duration, 1)\n",
    "#         })\n",
    "\n",
    "#     total_time = (time.time() - total_start) / 60\n",
    "    \n",
    "#     print(f\"\\n{'='*85}\")\n",
    "#     print(f\"📊 FINAL SCORECARD\")\n",
    "#     print(f\"{'='*85}\")\n",
    "#     df_results = pd.DataFrame(score_card)\n",
    "#     print(df_results.to_string(index=False))\n",
    "#     print(f\"{'='*85}\")\n",
    "#     print(f\"Total Correct: {correct_count} / 10\")\n",
    "#     print(f\"Accuracy:      {(correct_count/10)*100:.1f}%\")\n",
    "#     print(f\"Total Duration: {total_time:.2f} minutes\")\n",
    "#     print(f\"{'='*85}\\n\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # 3. EXECUTION\n",
    "# # ============================================================================\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     if 'predict' in globals():\n",
    "#         run_aimo3_reference_challenge()\n",
    "#     else:\n",
    "#         print(\"Error: 'predict' function not found. Please run your solver code first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b41cb1",
   "metadata": {
    "papermill": {
     "duration": 0.002283,
     "end_time": "2026-02-21T08:53:54.613560",
     "exception": false,
     "start_time": "2026-02-21T08:53:54.611277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "sourceId": 118448,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 13306865,
     "modelId": 422384,
     "modelInstanceId": 404485,
     "sourceId": 510391,
     "sourceType": "modelInstanceVersion"
    },
    {
     "sourceId": 289055161,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 448.60672,
   "end_time": "2026-02-21T08:53:55.433186",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-21T08:46:26.826466",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
